{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;;\" src='Figures/alinco.png' /></a>\n",
    "\n",
    "# <center> <font color= #000047> Módulo 1: Crear una Red Neuronal Recurrente en TensorFlow 2.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JL3SBH6PzDwV"
   },
   "source": [
    "## Paso 1: Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynShOu8nNtFt"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1557527181981,
     "user": {
      "displayName": "TechGuy Luka",
      "photoUrl": "https://lh3.googleusercontent.com/-v_8ixmE_SJc/AAAAAAAAAAI/AAAAAAAAAEY/QGGmNZURhdc/s64/photo.jpg",
      "userId": "12375685325186592450"
     },
     "user_tz": -120
    },
    "id": "Kw7-sPdOzf5l",
    "outputId": "43c449a9-bafd-408f-b6e1-17612b5fd375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JEjlM2EazOf0"
   },
   "source": [
    "## Paso 2: Pre procesado de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wB0tNtXJzTfA"
   },
   "source": [
    "### Configurar parámetros del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jw6_KU24SrYK"
   },
   "outputs": [],
   "source": [
    "number_of_words=20000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePywR8A4zaxT"
   },
   "source": [
    "### Carga del dataset de IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6kCTV_hjOKmE"
   },
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test, y_test) = imdb.load_data(num_words=number_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZKDNoTKzi5w"
   },
   "source": [
    "### Cortar secuencias de texto de la misma longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHcMNzv7Pd1s"
   },
   "outputs": [],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fcxd--ESP3Rh"
   },
   "outputs": [],
   "source": [
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7xDMP44Zz0dU"
   },
   "source": [
    "### Configurar parámetros de la capa de Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1557527197664,
     "user": {
      "displayName": "TechGuy Luka",
      "photoUrl": "https://lh3.googleusercontent.com/-v_8ixmE_SJc/AAAAAAAAAAI/AAAAAAAAAEY/QGGmNZURhdc/s64/photo.jpg",
      "userId": "12375685325186592450"
     },
     "user_tz": -120
    },
    "id": "nGHQ2upgQIGj",
    "outputId": "cd40fe5e-bd42-442a-801a-55e79865ab8c"
   },
   "outputs": [],
   "source": [
    "vocab_size=number_of_words\n",
    "embed_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VG6LBKGnz7jT"
   },
   "source": [
    "## Paso 3: Construir la Red Neuronal Recurrente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TUVnz-9K0DcW"
   },
   "source": [
    "### Definir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2GHzwk6OMrV"
   },
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lnXJZYR-0HXE"
   },
   "source": [
    "### Añadir la capa de embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWqC0DXbO9FU"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Embedding(vocab_size,embed_size, input_shape=(x_train.shape[1],)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CM-lpTZX1mEG"
   },
   "source": [
    "### Añadir la capa de LSTM\n",
    "\n",
    "- unidades: 128\n",
    "- función de activación: tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U numpy==1.18.5 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1557527201016,
     "user": {
      "displayName": "TechGuy Luka",
      "photoUrl": "https://lh3.googleusercontent.com/-v_8ixmE_SJc/AAAAAAAAAAI/AAAAAAAAAEY/QGGmNZURhdc/s64/photo.jpg",
      "userId": "12375685325186592450"
     },
     "user_tz": -120
    },
    "id": "5W7IXqhjQpAl",
    "outputId": "ca4438c1-f0a3-4742-9cb6-803920134d18"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.LSTM(units=128, activation='tanh'))\n",
    "#model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9T9M5Ult10XM"
   },
   "source": [
    "### Añadir la capa totalmente conectada de salida\n",
    "\n",
    "- unidades: 1\n",
    "- función de activación: sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xe1nHzq7Q91-"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWcqM4Yr2ALS"
   },
   "source": [
    "### Compilar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-z9ACOXcRUUN"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bPUvbfe2GJI"
   },
   "source": [
    "### Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9460,
     "status": "ok",
     "timestamp": 1557527214350,
     "user": {
      "displayName": "TechGuy Luka",
      "photoUrl": "https://lh3.googleusercontent.com/-v_8ixmE_SJc/AAAAAAAAAAI/AAAAAAAAAEY/QGGmNZURhdc/s64/photo.jpg",
      "userId": "12375685325186592450"
     },
     "user_tz": -120
    },
    "id": "9FqUTA1CRpQ8",
    "outputId": "0d496788-f042-4fb3-d7d9-18166d2cbc9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "196/196 [==============================] - 24s 120ms/step - loss: 0.4903 - accuracy: 0.7688\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 25s 128ms/step - loss: 0.2923 - accuracy: 0.8834\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 28s 143ms/step - loss: 0.2312 - accuracy: 0.9123\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 38s 191ms/step - loss: 0.1906 - accuracy: 0.9292\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 35s 178ms/step - loss: 0.1555 - accuracy: 0.9426\n",
      "Epoch 6/10\n",
      " 26/196 [==>...........................] - ETA: 28s - loss: 0.1120 - accuracy: 0.9606"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-wMo2wYpbCgb"
   },
   "source": [
    "### Evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3908,
     "status": "ok",
     "timestamp": 1557527267061,
     "user": {
      "displayName": "TechGuy Luka",
      "photoUrl": "https://lh3.googleusercontent.com/-v_8ixmE_SJc/AAAAAAAAAAI/AAAAAAAAAEY/QGGmNZURhdc/s64/photo.jpg",
      "userId": "12375685325186592450"
     },
     "user_tz": -120
    },
    "id": "a8kD_6q-RySO",
    "outputId": "4f792319-1095-42b8-c35a-fb8f2f5093e6"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test,y_test)\n",
    "print(f'Test accuracy : {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1557527277712,
     "user": {
      "displayName": "TechGuy Luka",
      "photoUrl": "https://lh3.googleusercontent.com/-v_8ixmE_SJc/AAAAAAAAAAI/AAAAAAAAAEY/QGGmNZURhdc/s64/photo.jpg",
      "userId": "12375685325186592450"
     },
     "user_tz": -120
    },
    "id": "C0XnUtS-cEeI",
    "outputId": "0d99df5f-717e-4751-c4dc-48e77d765056"
   },
   "outputs": [],
   "source": [
    "#mejorar el accuracy de la red 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fN9QK49W3C29"
   },
   "source": [
    "### Otro Ejemplo: Predecir el precio de las acciones de Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('Data/Google_Stock_Price_Train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train['Date'].min(),dataset_train['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = dataset_train.iloc[:,1:2].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesado de los datos\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=MinMaxScaler()\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizar los datos\n",
    "plt.figure(figsize=(6,7))\n",
    "plt.plot(training_set_scaled, color='r', label='Google Stock')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una estructura de datos que me permita añadir a la entrada de la RNN\n",
    "\n",
    "# crear un conjunto de datos de dimension 60, \n",
    "X_train=[]\n",
    "y_train=[]\n",
    "\n",
    "for i in range(60,training_set.shape[0]):\n",
    "    X_train.append(training_set_scaled[i-60:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])\n",
    "\n",
    "X_train, y_train = np.array(X_train),np.array(y_train)\n",
    "\n",
    "# reshape convertir la matriz a un tensor de 3D\n",
    "(batch_size,timesteps) = X_train.shape\n",
    "\n",
    "#tensor 3D\n",
    "X_train = np.reshape(X_train, (batch_size,timesteps,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construyendo la red\n",
    "\n",
    "model_stock = tf.keras.Sequential()\n",
    "model_stock.add(tf.keras.layers.LSTM(units=50,return_sequences=True, input_shape=(timesteps,1)))\n",
    "model_stock.add(tf.keras.layers.Dropout(0.2))\n",
    "model_stock.add(tf.keras.layers.LSTM(units=50,return_sequences=True))\n",
    "model_stock.add(tf.keras.layers.Dropout(0.2))\n",
    "model_stock.add(tf.keras.layers.LSTM(units=50))\n",
    "model_stock.add(tf.keras.layers.Dropout(0.2))\n",
    "model_stock.add(tf.keras.layers.Dense(units=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stock.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilar el modelo\n",
    "model_stock.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Entrenar al modelo\n",
    "model_stock.fit(X_train, y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stock.save('model_stock.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('Data/Google_Stock_Price_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stock_prices = dataset_test.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis=0)\n",
    "dataset_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_index = len(dataset_total) - len(dataset_test)\n",
    "inputs = dataset_total[first_day_index - 60:].values\n",
    "inputs=inputs.reshape(-1,1)\n",
    "\n",
    "#escalar los datos\n",
    "inputs = sc.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "\n",
    "for i in range(60,80):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# reshape convertir la matriz a un tensor de 3D\n",
    "(batch_size,timesteps) = X_test.shape\n",
    "\n",
    "#tensor 3D\n",
    "X_test = np.reshape(X_test, (batch_size,timesteps,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicción \n",
    "predicted_stock_price = model_stock.predict(X_test)\n",
    "# invertir el escalamiento\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizar los datos con la predicción\n",
    "plt.figure(figsize=(6,7))\n",
    "plt.plot(real_stock_prices, color='r', label='Real Google Stock')\n",
    "plt.plot(predicted_stock_price, color='g', label='Predicted Google Stock')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de texto usando RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se trabaja con texto en un modelo de lenguaje natural (recordar que los tokens son palabras o caracteres), usando cualquier red podríamos modelar la probabilidad del siguiente token (palabra) para construir un modelo de generación de texto. \n",
    "\n",
    "Este modelo de lenguaje natural podría capturar la estructura estadística del texto completo. Entonces, podríamos entrenar una red neuronal para predecir el siguiente carácter, ó de manera similar, podríamos entrenar al modelo para que prediga la siguiente palabra, dada una secuencia de palabras. En este apartado implementaremos un modelo a nivel de caracter.\n",
    "\n",
    "\n",
    "<img src=\"Figures/63.png\" alt=\"Grayscale Image\" width=\"600\">\n",
    "\n",
    "### Implementing in Tensorflow\n",
    "#### The Dataset\n",
    "Usaremos un conjunto de datos que contiene las obras de Shakespeare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "path = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(path,'r').read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "\n",
    "Antes del entrenamiento, necesitamos asignar cadenas a números, extraer secuencias parcialmente superpuestas y empaquetarlas en una matriz numpy 3D de forma (secuencias, maxlen, caracteres únicos). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(file_path):\n",
    "    text = open(file_path, 'rb').read().decode(encoding='utf-8')\n",
    "    vocab = sorted(set(text))\n",
    "    \n",
    "    # crear un mapeo de los caracteres único con indices enteros\n",
    "    char2indx = {u: i for i,u in enumerate(vocab)}\n",
    "    indx2char = np.array(vocab)\n",
    "    text_as_int = np.array([char2indx[c] for c in text])\n",
    "    \n",
    "    return text_as_int, vocab, char2indx, indx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text, target_text = chunk[:-1], chunk[1:]\n",
    "    return input_text, target_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(text_as_int, seq_length=100, batch_size=64, buffer_size=10000):\n",
    "    char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "    dataset = char_dataset.batch(seq_length+1, drop_remainder=True).map(split_input_target)\n",
    "    dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construyendo la RNN\n",
    "\n",
    "La red que construiremos será una red con una sola capa LSTM seguida de una ,capa densa con una función de activación softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim=256, rnn_units=1024, batch_size =64):\n",
    "    model=tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int, vocab, char2indx, indx2char = process_text(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size=len(vocab))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Train the model\n",
    "\n",
    "Usaremos la función de pérdida `categorical_crossentropy` para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dataset, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('gen_text.h5', save_format='h5')\n",
    "model = build_model(vocab_size=len(vocab), batch_size=1)\n",
    "model.load_weights('gen_text.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, char2indx, indx2char, start_string, generate_char_num=1000):\n",
    "    input_eval = [char2indx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated =[]\n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(generate_char_num):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions,0)\n",
    "        \n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], axis=0)\n",
    "        text_generated.append(indx2char[predicted_id])\n",
    "    \n",
    "    return start_string + ''.join(text_generated)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_string = input(\"Escriba el texto inicial: \")\n",
    "generated_text = generate_text(model, char2indx, indx2char, start_string=user_string, generate_char_num=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Colab 5 - Construir una Red Neuronal Recurrente en TensorFlow 2.0.ipynb",
   "provenance": [
    {
     "file_id": "12OM3ntGfd38dUqLJ-Nk82RwKTz3POWGa",
     "timestamp": 1564656346258
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
